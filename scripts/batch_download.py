#!/usr/bin/env python3
"""
æ‰¹é‡ä¸‹è½½è‚¡ç¥¨æ•°æ®è„šæœ¬ï¼ˆæ”¯æŒå¹¶è¡Œä¸‹è½½å’Œæ–­ç‚¹ç»­ä¼ ï¼‰

ç”¨æ³•ï¼š
    # ä¸²è¡Œä¸‹è½½ï¼ˆé»˜è®¤ï¼‰
    python scripts/batch_download.py --years 3

    # å¹¶è¡Œä¸‹è½½ï¼ˆæ¨è5çº¿ç¨‹ï¼‰
    python scripts/batch_download.py --years 3 --parallel 5

    # æ–­ç‚¹ç»­ä¼ ï¼ˆè·³è¿‡å·²ä¸‹è½½ï¼‰
    python scripts/batch_download.py --years 3 --resume --parallel 5

åŠŸèƒ½ï¼š
    - ä» stock_pool.yaml è¯»å–è‚¡ç¥¨åˆ—è¡¨
    - æ”¯æŒå¹¶è¡Œä¸‹è½½ï¼ˆconcurrent.futures.ThreadPoolExecutorï¼‰
    - æ”¯æŒæ–­ç‚¹ç»­ä¼ ï¼ˆæ£€æŸ¥å·²å­˜åœ¨çš„æ•°æ®æ–‡ä»¶ï¼‰
    - ç”Ÿæˆä¸‹è½½æŠ¥å‘Šï¼ˆJSON + Markdownï¼‰
"""

import argparse
import subprocess
import time
from pathlib import Path
import sys
from concurrent.futures import ThreadPoolExecutor, as_completed
from typing import List, Dict
import pandas as pd

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„ï¼Œä»¥ä¾¿å¯¼å…¥é…ç½®ç³»ç»Ÿ
sys.path.insert(0, str(Path(__file__).parent.parent))

# å¯¼å…¥é…ç½®ç³»ç»Ÿå’ŒIOå·¥å…·
from config import get_settings, Settings
from utils.io import save_json_with_metadata

# tqdmè¿›åº¦æ¡æ”¯æŒ
try:
    from tqdm import tqdm
    TQDM_AVAILABLE = True
except ImportError:
    TQDM_AVAILABLE = False
    print("âš ï¸  tqdmæœªå®‰è£…ï¼Œå°†ä¸æ˜¾ç¤ºè¿›åº¦æ¡ï¼ˆå¯é€‰å®‰è£…: pip install tqdmï¼‰")


def load_stock_pool(pool_name: str = 'medium_cap', settings: Settings = None) -> list:
    """
    ä»é…ç½®ç³»ç»ŸåŠ è½½è‚¡ç¥¨æ± ï¼ˆå·²è¿ç§»åˆ°Pydantic Settingsï¼‰

    Args:
        pool_name: è‚¡ç¥¨æ± åç§°ï¼ˆsmall_cap/medium_cap/legacy_test_poolï¼‰
        settings: Settingså®ä¾‹ï¼ˆå¯é€‰ï¼Œå¦‚ä¸æä¾›åˆ™è‡ªåŠ¨åŠ è½½ï¼‰

    Returns:
        list: è‚¡ç¥¨ä¿¡æ¯åˆ—è¡¨ï¼ˆdictæ ¼å¼ä»¥ä¿æŒå‘åå…¼å®¹ï¼‰
    """
    # è·å–é…ç½®
    if settings is None:
        settings = get_settings()

    try:
        # ä»é…ç½®ç³»ç»Ÿè·å–è‚¡ç¥¨æ± 
        stock_list = settings.stock_pool.get_pool(pool_name)

        # è½¬æ¢ä¸ºdictåˆ—è¡¨ä»¥ä¿æŒå‘åå…¼å®¹
        stocks = [
            {
                "symbol": stock.symbol,
                "name": stock.name,
                "industry": stock.industry,
                "sector": stock.sector
            }
            for stock in stock_list
        ]

        if not stocks:
            print(f"âŒ è‚¡ç¥¨æ±  {pool_name} ä¸ºç©º")
            sys.exit(1)

        print(f"âœ… ä»é…ç½®ç³»ç»ŸåŠ è½½ {pool_name}ï¼ˆ{len(stocks)} åªè‚¡ç¥¨ï¼‰")
        return stocks

    except Exception as e:
        print(f"âŒ åŠ è½½è‚¡ç¥¨æ± å¤±è´¥: {e}")
        sys.exit(1)


def is_already_downloaded(symbol: str, min_records: int = 500) -> bool:
    """
    æ£€æŸ¥è‚¡ç¥¨æ•°æ®æ˜¯å¦å·²å­˜åœ¨ä¸”å®Œæ•´

    Args:
        symbol: è‚¡ç¥¨ä»£ç ï¼ˆå¦‚ 000001.SZï¼‰
        min_records: æœ€å°è®°å½•æ•°é˜ˆå€¼ï¼ˆé»˜è®¤500ï¼Œçº¦2å¹´æ•°æ®ï¼‰

    Returns:
        bool: å¦‚æœæ•°æ®å­˜åœ¨ä¸”è®°å½•æ•°>=min_recordsï¼Œè¿”å›True
    """
    csv_path = Path.home() / ".qlib" / "qlib_data" / "cn_data" / f"{symbol}.csv"

    if not csv_path.exists():
        return False

    try:
        df = pd.read_csv(csv_path)
        return len(df) >= min_records
    except Exception:
        # å¦‚æœæ–‡ä»¶æŸåï¼Œè§†ä¸ºæœªä¸‹è½½
        return False


def download_stock(symbol: str, years: int, silent: bool = False) -> dict:
    """
    ä¸‹è½½å•åªè‚¡ç¥¨æ•°æ®

    Args:
        symbol: è‚¡ç¥¨ä»£ç 
        years: å›æº¯å¹´æ•°
        silent: æ˜¯å¦é™é»˜æ¨¡å¼ï¼ˆå¹¶è¡Œä¸‹è½½æ—¶ä½¿ç”¨ï¼‰

    Returns:
        dict: ä¸‹è½½ç»“æœ {symbol, status, elapsed, message}
    """
    if not silent:
        print(f"\n{'='*60}")
        print(f"æ­£åœ¨ä¸‹è½½: {symbol}")
        print(f"{'='*60}")

    start_time = time.time()

    try:
        result = subprocess.run(
            [
                "python3",
                "scripts/akshare-to-qlib-converter.py",
                "--symbol", symbol,
                "--years", str(years),
                "--adjust", "qfq",
            ],
            capture_output=True,
            text=True,
            timeout=120,
        )

        elapsed = time.time() - start_time

        if result.returncode == 0:
            if not silent:
                print(f"âœ… {symbol} ä¸‹è½½æˆåŠŸ (è€—æ—¶ {elapsed:.1f}s)")
            return {
                "symbol": symbol,
                "status": "success",
                "elapsed": elapsed,
                "message": "ä¸‹è½½æˆåŠŸ"
            }
        else:
            if not silent:
                print(f"âŒ {symbol} ä¸‹è½½å¤±è´¥")
                print(f"é”™è¯¯: {result.stderr}")
            return {
                "symbol": symbol,
                "status": "failed",
                "elapsed": elapsed,
                "message": result.stderr.strip()[:200]  # é™åˆ¶é”™è¯¯ä¿¡æ¯é•¿åº¦
            }

    except subprocess.TimeoutExpired:
        if not silent:
            print(f"âŒ {symbol} ä¸‹è½½è¶…æ—¶ (>120s)")
        return {
            "symbol": symbol,
            "status": "timeout",
            "elapsed": 120,
            "message": "ä¸‹è½½è¶…æ—¶"
        }
    except Exception as e:
        if not silent:
            print(f"âŒ {symbol} ä¸‹è½½å‡ºé”™: {e}")
        return {
            "symbol": symbol,
            "status": "error",
            "elapsed": 0,
            "message": str(e)
        }


def download_with_parallel(stocks: List[dict], years: int, max_workers: int = 3,
                          resume: bool = False) -> List[dict]:
    """
    å¹¶è¡Œä¸‹è½½å¤šåªè‚¡ç¥¨

    Args:
        stocks: è‚¡ç¥¨åˆ—è¡¨
        years: å›æº¯å¹´æ•°
        max_workers: æœ€å¤§å¹¶å‘çº¿ç¨‹æ•°ï¼ˆé»˜è®¤3ï¼Œæ¨è3-5ï¼‰
        resume: æ˜¯å¦å¯ç”¨æ–­ç‚¹ç»­ä¼ 

    Returns:
        List[dict]: ä¸‹è½½ç»“æœåˆ—è¡¨
    """
    results = []
    total = len(stocks)

    # è¿‡æ»¤å·²ä¸‹è½½çš„è‚¡ç¥¨ï¼ˆå¦‚å¯ç”¨resumeï¼‰
    if resume:
        print("\nğŸ” æ£€æŸ¥å·²ä¸‹è½½çš„è‚¡ç¥¨...")
        to_download = []
        skipped = []

        for stock in stocks:
            symbol = stock["symbol"]
            if is_already_downloaded(symbol, min_records=500):
                skipped.append(symbol)
                results.append({
                    "symbol": symbol,
                    "status": "skipped",
                    "elapsed": 0,
                    "message": "å·²å­˜åœ¨ï¼Œè·³è¿‡"
                })
            else:
                to_download.append(stock)

        print(f"âœ… å·²ä¸‹è½½: {len(skipped)} åª")
        print(f"ğŸ“¥ å¾…ä¸‹è½½: {len(to_download)} åª")

        if not to_download:
            print("\nğŸ‰ æ‰€æœ‰è‚¡ç¥¨å·²ä¸‹è½½å®Œæˆï¼")
            return results
    else:
        to_download = stocks

    # å¹¶è¡Œä¸‹è½½
    print(f"\nğŸš€ å¼€å§‹å¹¶è¡Œä¸‹è½½ï¼ˆ{max_workers} çº¿ç¨‹ï¼‰...\n")

    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        # æäº¤æ‰€æœ‰ä»»åŠ¡
        futures = {
            executor.submit(download_stock, stock["symbol"], years, silent=True): stock
            for stock in to_download
        }

        # ä½¿ç”¨è¿›åº¦æ¡ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if TQDM_AVAILABLE:
            iterator = tqdm(as_completed(futures), total=len(to_download),
                          desc="ä¸‹è½½è¿›åº¦", unit="åª")
        else:
            iterator = as_completed(futures)

        # æ”¶é›†ç»“æœ
        for future in iterator:
            stock = futures[future]
            try:
                result = future.result()
                results.append(result)

                # å®æ—¶æ˜¾ç¤ºç»“æœ
                status_emoji = "âœ…" if result["status"] == "success" else "âŒ"
                if not TQDM_AVAILABLE:
                    print(f"{status_emoji} {result['symbol']} - {result['status']}")

            except Exception as e:
                # å¼‚å¸¸å¤„ç†
                results.append({
                    "symbol": stock["symbol"],
                    "status": "error",
                    "elapsed": 0,
                    "message": f"çº¿ç¨‹å¼‚å¸¸: {str(e)}"
                })

        # æ·»åŠ çŸ­æš‚å»¶è¿Ÿï¼Œé¿å…APIé™æµ
        time.sleep(1)

    return results


def generate_report(results: List[dict], output_dir: Path, parallel_workers: int = 1):
    """
    ç”Ÿæˆä¸‹è½½æŠ¥å‘Šï¼ˆJSON + Markdownï¼‰

    Args:
        results: ä¸‹è½½ç»“æœåˆ—è¡¨
        output_dir: è¾“å‡ºç›®å½•ï¼ˆé»˜è®¤ results/ï¼‰
        parallel_workers: å¹¶å‘çº¿ç¨‹æ•°ï¼ˆç”¨äºæŠ¥å‘Šå±•ç¤ºï¼‰
    """
    total = len(results)
    success = sum(1 for r in results if r["status"] == "success")
    skipped = sum(1 for r in results if r["status"] == "skipped")
    failed = total - success - skipped
    total_time = sum(r["elapsed"] for r in results)

    # ç»Ÿè®¡å¤±è´¥çš„è‚¡ç¥¨ä»£ç 
    failed_symbols = [r["symbol"] for r in results if r["status"] not in ("success", "skipped")]

    # ç”ŸæˆJSONæŠ¥å‘Šï¼ˆä½¿ç”¨utils.ioå·¥å…·ï¼‰
    json_data = {
        "total": total,
        "success": success,
        "failed": failed,
        "skipped": skipped,
        "failed_symbols": failed_symbols,
        "duration_seconds": round(total_time, 2),
        "parallel_workers": parallel_workers,
        "details": results
    }

    json_path = output_dir / "batch_download_report.json"
    save_json_with_metadata(json_data, json_path, phase="Phase 8.2", version="1.1.0")

    # ç”ŸæˆMarkdownæŠ¥å‘Š
    md_path = output_dir / "batch_download_report.md"

    report = f"""# æ‰¹é‡ä¸‹è½½æŠ¥å‘Š

## æ¦‚è§ˆ
- **æ€»è®¡**: {total} åªè‚¡ç¥¨
- **æˆåŠŸ**: {success} åª ({success/total*100:.1f}%)
- **è·³è¿‡**: {skipped} åª ({skipped/total*100:.1f}%)
- **å¤±è´¥**: {failed} åª ({failed/total*100:.1f}%)
- **æ€»è€—æ—¶**: {total_time:.1f} ç§’
- **å¹³å‡è€—æ—¶**: {total_time/max(total-skipped, 1):.1f} ç§’/åªï¼ˆä¸å«è·³è¿‡ï¼‰
- **å¹¶å‘çº¿ç¨‹**: {parallel_workers} ä¸ª

## è¯¦ç»†ç»“æœ

| è‚¡ç¥¨ä»£ç  | çŠ¶æ€ | è€—æ—¶ | å¤‡æ³¨ |
|----------|------|------|------|
"""

    for r in results:
        status_map = {
            "success": "âœ…",
            "skipped": "â­ï¸",
            "failed": "âŒ",
            "timeout": "â±ï¸",
            "error": "ğŸ’¥"
        }
        status_emoji = status_map.get(r["status"], "â“")
        report += f"| {r['symbol']} | {status_emoji} {r['status']} | {r['elapsed']:.1f}s | {r['message'][:50]} |\n"

    if failed > 0:
        report += "\n## å¤±è´¥è¯¦æƒ…\n\n"
        for r in results:
            if r["status"] not in ("success", "skipped"):
                report += f"### {r['symbol']}\n"
                report += f"```\n{r['message']}\n```\n\n"

    with open(md_path, "w", encoding="utf-8") as f:
        f.write(report)

    # ç»ˆç«¯è¾“å‡º
    print(f"\n{'='*60}")
    print(f"ğŸ“Š ä¸‹è½½æŠ¥å‘Šå·²ç”Ÿæˆ")
    print(f"  - JSON: {json_path}")
    print(f"  - Markdown: {md_path}")
    print(f"{'='*60}")
    print(f"æˆåŠŸ: {success}/{total}  |  è·³è¿‡: {skipped}/{total}  |  å¤±è´¥: {failed}/{total}")
    print(f"æ€»è€—æ—¶: {total_time:.1f}s  |  å¹¶å‘: {parallel_workers} çº¿ç¨‹")
    print(f"{'='*60}")


def main():
    parser = argparse.ArgumentParser(
        description="æ‰¹é‡ä¸‹è½½è‚¡ç¥¨æ•°æ®ï¼ˆæ”¯æŒå¹¶è¡Œä¸‹è½½å’Œæ–­ç‚¹ç»­ä¼ ï¼‰",
        epilog="""
ç¤ºä¾‹ç”¨æ³•ï¼š
  # ä¸²è¡Œä¸‹è½½ï¼ˆé»˜è®¤ï¼‰
  python scripts/batch_download.py --years 3

  # å¹¶è¡Œä¸‹è½½ï¼ˆæ¨è5çº¿ç¨‹ï¼‰
  python scripts/batch_download.py --years 3 --parallel 5

  # æ–­ç‚¹ç»­ä¼ ï¼ˆè·³è¿‡å·²ä¸‹è½½ï¼‰
  python scripts/batch_download.py --years 3 --resume --parallel 5

  # ä½¿ç”¨large_capæ± ï¼ˆ100åªè‚¡ç¥¨ï¼‰
  python scripts/batch_download.py --pool large_cap --years 3 --parallel 5 --resume
        """,
        formatter_class=argparse.RawDescriptionHelpFormatter
    )

    parser.add_argument(
        "--years", type=int, default=3,
        help="å›æº¯å¹´æ•°ï¼ˆé»˜è®¤ 3 å¹´ï¼‰"
    )

    # ä»é…ç½®ç³»ç»Ÿè·å–å¯ç”¨æ± åˆ—è¡¨
    valid_pools = ['small_cap', 'medium_cap', 'large_cap', 'legacy_test_pool']

    parser.add_argument(
        "--pool", type=str, default='medium_cap',
        choices=valid_pools,
        help=f'è‚¡ç¥¨æ± é€‰æ‹©ï¼ˆå¯ç”¨: {", ".join(valid_pools)}ï¼‰'
    )

    parser.add_argument(
        "--parallel", type=int, default=1,
        help="å¹¶å‘ä¸‹è½½æ•°ï¼ˆæ¨è3-5ï¼Œé»˜è®¤1=ä¸²è¡Œï¼‰"
    )

    parser.add_argument(
        "--resume", action='store_true',
        help="æ–­ç‚¹ç»­ä¼ ï¼Œè·³è¿‡å·²ä¸‹è½½çš„è‚¡ç¥¨ï¼ˆæ£€æŸ¥~/.qlib/qlib_data/cn_data/ï¼‰"
    )

    args = parser.parse_args()

    # éªŒè¯å¹¶å‘å‚æ•°
    if args.parallel < 1 or args.parallel > 10:
        print("âŒ --parallel å‚æ•°èŒƒå›´åº”ä¸º 1-10")
        sys.exit(1)

    # ä»é…ç½®ç³»ç»ŸåŠ è½½è‚¡ç¥¨æ± 
    stocks = load_stock_pool(args.pool)

    if not stocks:
        print("âŒ è‚¡ç¥¨æ± ä¸ºç©º")
        sys.exit(1)

    # æ˜¾ç¤ºé…ç½®ä¿¡æ¯
    print(f"\n{'='*60}")
    print(f"ğŸ“‹ ä¸‹è½½é…ç½®")
    print(f"{'='*60}")
    print(f"è‚¡ç¥¨æ± : {args.pool} ({len(stocks)} åª)")
    print(f"å›æº¯å¹´æ•°: {args.years} å¹´")
    print(f"å¹¶å‘æ¨¡å¼: {'ä¸²è¡Œ' if args.parallel == 1 else f'å¹¶è¡Œ ({args.parallel} çº¿ç¨‹)'}")
    print(f"æ–­ç‚¹ç»­ä¼ : {'å¯ç”¨' if args.resume else 'ç¦ç”¨'}")
    print(f"{'='*60}\n")

    # æ‰§è¡Œä¸‹è½½ï¼ˆä¸²è¡Œ or å¹¶è¡Œï¼‰
    start_time = time.time()

    if args.parallel > 1:
        # å¹¶è¡Œä¸‹è½½
        results = download_with_parallel(stocks, args.years, args.parallel, args.resume)
    else:
        # ä¸²è¡Œä¸‹è½½ï¼ˆä¿ç•™åŸæœ‰é€»è¾‘ï¼‰
        results = []

        # æ–­ç‚¹ç»­ä¼ æ£€æŸ¥
        if args.resume:
            print("\nğŸ” æ£€æŸ¥å·²ä¸‹è½½çš„è‚¡ç¥¨...")
            to_download = []
            skipped_count = 0

            for stock in stocks:
                symbol = stock["symbol"]
                if is_already_downloaded(symbol, min_records=500):
                    skipped_count += 1
                    results.append({
                        "symbol": symbol,
                        "status": "skipped",
                        "elapsed": 0,
                        "message": "å·²å­˜åœ¨ï¼Œè·³è¿‡"
                    })
                else:
                    to_download.append(stock)

            print(f"âœ… å·²ä¸‹è½½: {skipped_count} åª")
            print(f"ğŸ“¥ å¾…ä¸‹è½½: {len(to_download)} åª\n")

            if not to_download:
                print("\nğŸ‰ æ‰€æœ‰è‚¡ç¥¨å·²ä¸‹è½½å®Œæˆï¼")
                total_time = time.time() - start_time
                generate_report(results, Path("results"), parallel_workers=1)
                return
        else:
            to_download = stocks

        # ä½¿ç”¨è¿›åº¦æ¡ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        iterator = tqdm(to_download, desc="ä¸‹è½½è¿›åº¦", unit="åª") if TQDM_AVAILABLE else to_download

        for i, stock in enumerate(iterator, 1):
            symbol = stock["symbol"]
            name = stock.get("name", "")
            sector = stock.get("sector", "")

            if not TQDM_AVAILABLE:
                print(f"\n[{i}/{len(to_download)}] {symbol} - {name} ({sector})")

            result = download_stock(symbol, args.years, silent=TQDM_AVAILABLE)
            results.append(result)

            # é¿å…è¯·æ±‚è¿‡å¿«ï¼Œä¼‘æ¯ 2 ç§’
            if i < len(to_download):
                time.sleep(2)

    # è®¡ç®—æ€»è€—æ—¶
    total_time = time.time() - start_time

    # ç”ŸæˆæŠ¥å‘Š
    output_dir = Path("results")
    output_dir.mkdir(exist_ok=True)

    generate_report(results, output_dir, parallel_workers=args.parallel)

    # æ€§èƒ½æ€»ç»“
    print(f"\nğŸ æ‰¹é‡ä¸‹è½½å®Œæˆï¼æ€»è€—æ—¶: {total_time/60:.1f} åˆ†é’Ÿ")


if __name__ == "__main__":
    main()
