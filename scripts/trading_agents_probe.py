#!/usr/bin/env python3
"""
Phase 9A: TradingAgents AIæ¢é’ˆ - æœ€å°å¯è¡Œå•å…ƒ

åŠŸèƒ½ï¼š
- è¯»å– phase6d çœŸå®å›æµ‹ç»“æœ
- è°ƒç”¨ gpt-4.1-mini å¯¹è‚¡ç¥¨è¿›è¡ŒæŠ€æœ¯åˆ†æè¯„åˆ†
- è¾“å‡º AIè¯„åˆ† vs å®é™…æ”¶ç›Šå¯¹æ¯”

ç”¨æ³•ï¼š
    python scripts/trading_agents_probe.py
    python scripts/trading_agents_probe.py --max-samples 5
    python scripts/trading_agents_probe.py --config config/ai_agents_local.yaml
"""

import os
import sys
import re
import yaml
import pandas as pd
import numpy as np
import argparse
import json
from pathlib import Path
from datetime import datetime
import logging

# å¯¼å…¥ OpenAIï¼ˆå…¼å®¹æœ€æ–°ç‰ˆæœ¬ï¼‰
try:
    from openai import OpenAI
except ImportError:
    print("âŒ é”™è¯¯ï¼šæœªå®‰è£… openai åº“")
    print("è¯·è¿è¡Œï¼špip install openai")
    sys.exit(1)


# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def load_config(config_path='config/ai_agents.yaml'):
    """
    åŠ è½½é…ç½®æ–‡ä»¶ï¼Œæ”¯æŒç¯å¢ƒå˜é‡æ›¿æ¢

    ä¼˜å…ˆçº§ï¼šai_agents_local.yaml > ai_agents.yaml
    """
    # å°è¯•æœ¬åœ°é…ç½®
    local_config_path = config_path.replace('.yaml', '_local.yaml')
    if os.path.exists(local_config_path):
        config_path = local_config_path
        logger.info(f"âœ“ ä½¿ç”¨æœ¬åœ°é…ç½®: {local_config_path}")

    if not os.path.exists(config_path):
        raise FileNotFoundError(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")

    with open(config_path, 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)

    # ç¯å¢ƒå˜é‡æ›¿æ¢
    api_key = config['openai']['api_key']
    if api_key.startswith('${') and api_key.endswith('}'):
        env_var = api_key[2:-1]
        api_key = os.getenv(env_var)
        if not api_key:
            raise ValueError(
                f"ç¯å¢ƒå˜é‡ {env_var} æœªè®¾ç½®\n"
                f"è¯·è¿è¡Œ: export {env_var}=your_api_key"
            )
        config['openai']['api_key'] = api_key

    logger.info(f"âœ“ é…ç½®åŠ è½½æˆåŠŸ: {config_path}")
    return config


def load_stock_pool(pool_path='stock_pool.yaml'):
    """
    åŠ è½½è‚¡ç¥¨æ± ï¼Œæå–è‚¡ç¥¨å…ƒä¿¡æ¯

    Returns:
        dict: {symbol: {name, industry, sector}}
    """
    if not os.path.exists(pool_path):
        raise FileNotFoundError(f"è‚¡ç¥¨æ± æ–‡ä»¶ä¸å­˜åœ¨: {pool_path}")

    with open(pool_path, 'r', encoding='utf-8') as f:
        data = yaml.safe_load(f)

    stock_info = {}

    # å¤„ç† medium_capï¼ˆåŒ…å« inherit_fromï¼‰
    if 'medium_cap' in data['stock_pools']:
        pool = data['stock_pools']['medium_cap']

        # ç»§æ‰¿ small_cap
        if pool.get('inherit_from') == 'small_cap':
            for stock in data['stock_pools']['small_cap']:
                stock_info[stock['symbol']] = {
                    'name': stock['name'],
                    'industry': stock['industry'],
                    'sector': stock['sector']
                }

        # æ·»åŠ é¢å¤–è‚¡ç¥¨
        if 'additional' in pool:
            for stock in pool['additional']:
                stock_info[stock['symbol']] = {
                    'name': stock['name'],
                    'industry': stock['industry'],
                    'sector': stock['sector']
                }

    # å…œåº•ï¼šåŠ è½½ small_cap
    if not stock_info and 'small_cap' in data['stock_pools']:
        for stock in data['stock_pools']['small_cap']:
            stock_info[stock['symbol']] = {
                'name': stock['name'],
                'industry': stock['industry'],
                'sector': stock['sector']
            }

    logger.info(f"âœ“ è‚¡ç¥¨æ± åŠ è½½æˆåŠŸ: {len(stock_info)}åªè‚¡ç¥¨")
    return stock_info


def calculate_ma(symbol, date, period=5, data_dir='~/.qlib/qlib_data/cn_data'):
    """
    è®¡ç®—ç§»åŠ¨å¹³å‡çº¿ï¼ˆä»Qlibæ•°æ®ï¼‰

    Args:
        symbol: è‚¡ç¥¨ä»£ç 
        date: ç›®æ ‡æ—¥æœŸï¼ˆpd.Timestampï¼‰
        period: MAå‘¨æœŸ
        data_dir: Qlibæ•°æ®ç›®å½•

    Returns:
        float: MAå€¼ï¼Œå¦‚æœå¤±è´¥è¿”å›None
    """
    try:
        data_dir = os.path.expanduser(data_dir)
        file_path = os.path.join(data_dir, f'{symbol}.csv')

        if not os.path.exists(file_path):
            logger.warning(f"âš ï¸  æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
            return None

        df = pd.read_csv(file_path)
        df['date'] = pd.to_datetime(df['date'])
        df = df.set_index('date').sort_index()

        # æ‰¾åˆ°ç›®æ ‡æ—¥æœŸæˆ–ä¹‹å‰æœ€è¿‘çš„äº¤æ˜“æ—¥
        available_dates = df.index[df.index <= date]
        if len(available_dates) == 0:
            return None

        target_date = available_dates[-1]

        # è®¡ç®—MA
        end_idx = df.index.get_loc(target_date)
        start_idx = max(0, end_idx - period + 1)

        if end_idx - start_idx + 1 < period:
            return None

        ma_value = df.iloc[start_idx:end_idx + 1]['close'].mean()
        return round(ma_value, 2)

    except Exception as e:
        logger.warning(f"âš ï¸  è®¡ç®— MA{period} å¤±è´¥ ({symbol}): {e}")
        return None


def parse_ai_score(content):
    """
    å¢å¼ºçš„AIè¯„åˆ†è§£æï¼Œæ”¯æŒå¤šç§æ ¼å¼

    æ”¯æŒæ ¼å¼ï¼š
    - "8åˆ†"
    - "è¯„åˆ†ï¼š8" æˆ– "è¯„åˆ†: 8"
    - "8/10"
    - "8. ç†ç”±..."

    Args:
        content: AIè¿”å›çš„æ–‡æœ¬å†…å®¹

    Returns:
        int: è¯„åˆ†ï¼ˆ1-10ï¼‰ï¼Œè§£æå¤±è´¥è¿”å›None
    """
    patterns = [
        r'(\d+)\s*åˆ†',              # "8åˆ†"
        r'è¯„åˆ†[ï¼š:]\s*(\d+)',        # "è¯„åˆ†ï¼š8" æˆ– "è¯„åˆ†: 8"
        r'(\d+)\s*/\s*10',           # "8/10"
        r'^(\d+)[\s\.\|]',           # å¼€å¤´æ•°å­—å¦‚ "8. ç†ç”±..."
    ]

    for pattern in patterns:
        match = re.search(pattern, content)
        if match:
            score = int(match.group(1))
            if 1 <= score <= 10:
                return score

    logger.warning(f"âš ï¸  æ— æ³•è§£æè¯„åˆ†: {content[:50]}...")
    return None


def analyze_stock_with_ai(context, config):
    """
    è°ƒç”¨ OpenAI API åˆ†æè‚¡ç¥¨

    Args:
        context: dict {symbol, name, momentum_20d, ma5, ma10, industry, sector}
        config: é…ç½®å­—å…¸

    Returns:
        dict: {ai_score, ai_reason, cost_usd, success}
    """
    try:
        client = OpenAI(
            api_key=config['openai']['api_key'],
            base_url=config['openai']['base_url']
        )

        # æ„é€ prompt
        prompt_template = config['agents']['technical_analyst']['prompt_template']
        prompt = prompt_template.format(**context)

        # è°ƒç”¨API
        response = client.chat.completions.create(
            model=config['openai']['model'],
            messages=[{"role": "user", "content": prompt}],
            temperature=config['openai']['temperature'],
            max_tokens=config['openai']['max_tokens'],
            timeout=config['openai'].get('timeout', 10)
        )

        # è§£æå“åº”
        content = response.choices[0].message.content.strip()
        usage = response.usage

        # è®¡ç®—æˆæœ¬ï¼ˆgpt-4.1-mini: $0.15/1M input, $0.60/1M outputï¼‰
        cost_usd = (
            usage.prompt_tokens * 0.00015 / 1000 +
            usage.completion_tokens * 0.0006 / 1000
        )

        # æå–è¯„åˆ†ï¼ˆä½¿ç”¨å¢å¼ºçš„è§£æå‡½æ•°ï¼‰
        ai_score = parse_ai_score(content)

        # æå–ç†ç”±ï¼ˆå»é™¤è¯„åˆ†éƒ¨åˆ†ï¼Œä¿ç•™ç†ç”±ï¼‰
        ai_reason = re.sub(r'.*?(\d+)\s*[åˆ†/:].*?[:ï¼š]?\s*', '', content)
        ai_reason = ai_reason.replace('\n', ' ').strip()[:50]  # é™åˆ¶é•¿åº¦

        logger.info(f"  âœ“ {context['symbol']}: è¯„åˆ†={ai_score}, æˆæœ¬=${cost_usd:.6f}")

        return {
            'ai_score': ai_score,
            'ai_reason': ai_reason,
            'cost_usd': cost_usd,
            'success': True
        }

    except Exception as e:
        logger.error(f"  âŒ {context.get('symbol', 'unknown')}: {e}")
        return {
            'ai_score': None,
            'ai_reason': f"APIé”™è¯¯: {str(e)[:30]}",
            'cost_usd': 0.0,
            'success': False
        }


def main():
    parser = argparse.ArgumentParser(description='Phase 9A: AIæ¢é’ˆåˆ†æ')
    parser.add_argument('--config', default='config/ai_agents.yaml',
                       help='é…ç½®æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--max-samples', type=int, default=None,
                       help='æœ€å¤§åˆ†æè‚¡ç¥¨æ•°ï¼ˆé»˜è®¤ï¼šé…ç½®æ–‡ä»¶ä¸­çš„å€¼ï¼‰')
    parser.add_argument('--backtest-file', default='results/phase6d_profit_distribution.csv',
                       help='å›æµ‹ç»“æœæ–‡ä»¶')
    args = parser.parse_args()

    logger.info("=" * 70)
    logger.info("Phase 9A: TradingAgents AIæ¢é’ˆå¯åŠ¨")
    logger.info("=" * 70)

    # 1. åŠ è½½é…ç½®
    config = load_config(args.config)
    max_samples = args.max_samples or config['probe']['max_samples']

    # 2. åŠ è½½è‚¡ç¥¨æ± 
    stock_info = load_stock_pool()

    # 3. åŠ è½½å›æµ‹ç»“æœ
    if not os.path.exists(args.backtest_file):
        raise FileNotFoundError(f"å›æµ‹ç»“æœæ–‡ä»¶ä¸å­˜åœ¨: {args.backtest_file}")

    backtest_df = pd.read_csv(args.backtest_file)
    backtest_df['start_date'] = pd.to_datetime(backtest_df['start_date'])
    backtest_df['end_date'] = pd.to_datetime(backtest_df['end_date'])

    logger.info(f"âœ“ å›æµ‹æ•°æ®åŠ è½½: {len(backtest_df)}æ¡è®°å½•")

    # 4. é‡‡æ ·ï¼ˆå–å‰Næ¡ï¼‰
    sample_df = backtest_df.head(max_samples).copy()
    logger.info(f"âœ“ é‡‡æ ·æ•°é‡: {len(sample_df)}æ¡")
    logger.info("")

    # 5. é€æ¡åˆ†æ
    results = []
    total_cost = 0.0

    for idx, row in sample_df.iterrows():
        symbol = row['symbol']

        # è·å–è‚¡ç¥¨å…ƒä¿¡æ¯
        info = stock_info.get(symbol, {
            'name': symbol,
            'industry': 'æœªçŸ¥',
            'sector': 'æœªçŸ¥'
        })

        # è®¡ç®—MAï¼ˆä½¿ç”¨æŒä»“æœŸç»“æŸæ—¥æœŸï¼‰
        ma5 = calculate_ma(symbol, row['end_date'], period=5)
        ma10 = calculate_ma(symbol, row['end_date'], period=10)

        # å¦‚æœMAè®¡ç®—å¤±è´¥ï¼Œè·³è¿‡
        if ma5 is None or ma10 is None:
            logger.warning(f"  âš ï¸  {symbol}: MAæ•°æ®ä¸è¶³ï¼Œè·³è¿‡")
            continue

        # æ„é€ åˆ†æä¸Šä¸‹æ–‡
        context = {
            'symbol': symbol,
            'name': info['name'],
            'momentum_20d': row['return_pct'] / 100,  # è½¬æ¢ä¸ºå°æ•°
            'ma5': ma5,
            'ma10': ma10,
            'industry': info['industry'],
            'sector': info['sector']
        }

        # è°ƒç”¨AIåˆ†æ
        ai_result = analyze_stock_with_ai(context, config)

        # æ±‡æ€»ç»“æœ
        results.append({
            'symbol': symbol,
            'name': info['name'],
            'period_start': row['start_date'].strftime('%Y-%m-%d'),
            'period_end': row['end_date'].strftime('%Y-%m-%d'),
            'momentum_20d': row['return_pct'],
            'ma5': ma5,
            'ma10': ma10,
            'ai_score': ai_result['ai_score'],
            'ai_reason': ai_result['ai_reason'],
            'actual_return': row['return_pct'],
            'cost_usd': ai_result['cost_usd']
        })

        total_cost += ai_result['cost_usd']

    # 6. è¾“å‡ºCSV
    if not results:
        logger.error("âŒ æ²¡æœ‰æˆåŠŸåˆ†æçš„æ•°æ®")
        sys.exit(1)

    result_df = pd.DataFrame(results)
    csv_path = config['output']['csv_path']
    result_df.to_csv(csv_path, index=False, encoding='utf-8')
    logger.info("")
    logger.info(f"âœ“ CSVè¾“å‡º: {csv_path}")

    # 7. ç”Ÿæˆæ±‡æ€»JSON
    summary = {
        'total_samples': len(results),
        'success_count': sum(1 for r in results if r['ai_score'] is not None),
        'total_cost_usd': round(total_cost, 6),
        'avg_cost_per_sample': round(total_cost / len(results), 6),
        'ai_score_stats': {
            'mean': round(result_df['ai_score'].mean(), 2),
            'std': round(result_df['ai_score'].std(), 2),
            'min': int(result_df['ai_score'].min()),
            'max': int(result_df['ai_score'].max())
        },
        'correlation': {
            'ai_score_vs_return': round(
                result_df['ai_score'].corr(result_df['actual_return']), 3
            ) if len(result_df) > 1 else None,
            'sample_size': len(result_df),
            'warning': 'âš ï¸ æ ·æœ¬é‡<20ï¼Œç›¸å…³æ€§ä»…ä¾›å‚è€ƒï¼Œä¸å…·ç»Ÿè®¡æ˜¾è‘—æ€§' if len(result_df) < 20 else None
        },
        'config': {
            'model': config['openai']['model'],
            'max_samples': max_samples,
            'backtest_file': args.backtest_file
        },
        'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    }

    summary_path = config['output']['summary_path']
    with open(summary_path, 'w', encoding='utf-8') as f:
        json.dump(summary, f, indent=2, ensure_ascii=False)

    logger.info(f"âœ“ JSONæ±‡æ€»: {summary_path}")
    logger.info("")
    logger.info("=" * 70)
    logger.info("ğŸ“Š åˆ†ææ±‡æ€»")
    logger.info("=" * 70)
    logger.info(f"æ€»æ ·æœ¬æ•°: {summary['total_samples']}")
    logger.info(f"æˆåŠŸæ•°: {summary['success_count']}")
    logger.info(f"æ€»æˆæœ¬: ${summary['total_cost_usd']:.6f}")
    logger.info(f"AIè¯„åˆ†å‡å€¼: {summary['ai_score_stats']['mean']:.2f}")
    logger.info(f"AIè¯„åˆ† vs å®é™…æ”¶ç›Šç›¸å…³æ€§: {summary['correlation']['ai_score_vs_return']:.3f}")
    logger.info("=" * 70)
    logger.info("âœ… Phase 9A AIæ¢é’ˆåˆ†æå®Œæˆ")


if __name__ == '__main__':
    main()
